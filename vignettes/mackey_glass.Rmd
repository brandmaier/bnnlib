---
title: "Mackey Glass"
author: "Andreas M. Brandmaier"
date: "12/15/2019"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Setup

First, we load the shared library.

```{r load, echo=TRUE}
library(bnnlib)

```

This is the Mackey-Glass time series: 

```{r}
x <- read.csv("../datasets/mackey-glass.dat")[,1]
x <- x[seq(1,length(x),2)] # take every other
dat <- data.frame(x=1:length(x),y=x)
dat1 <- dat[1:500,]
dat2 <- dat[500:1000,]
library(ggplot2)
ggplot(data=dat, mapping = aes(x=x,y=y) )+geom_line()+
  theme_minimal()+ ggtitle("Mackey Glass Series","Observations 1 to 500")
ggplot(data=dat2, mapping = aes(x=x,y=y) )+geom_line()+ 
  theme_minimal()+ ggtitle("Mackey Glass Series","Observations 500 to 1000")

```

You can also embed plots, for example:

```{r training, echo=FALSE}

connectivity = .8 # between 0 and 1
hidden_layer_size = 10
num_backward_connections = 5*hidden_layer_size

#network = NetworkFactory_create_random_gate_network(1,hidden_layer_size,1,
#			connectivity,num_backward_connections);

network = LSTMNetwork(1, 10, 1);

 training_set = SequenceSet("../datasets/mackey-glass.dat");

SequenceSet_scale_to_minmax(training_set, -1,+1);

trainer = ImprovedRPropTrainer(network);
#trainer = ARPropTrainer(network)
		
	Trainer_learning_rate_set( trainer, 0.0001 );
```

Train the network and plot training error

```{r}

#	trainer->abort_criteria.push_back( new ConvergenceCriterion(10e-7) );

#Trainer_add_abort_criterion(trainer, ConvergenceCriterion(.0001), 1)

	Trainer_train2(trainer, training_set, 500)

#	GnuplotGenerator_plot_vector__SWIG_0("Training Error", Trainer_error_train_get(trainer))

source("../R/plotTrainingerror.R")
plotTrainingerror(trainer)
```

Forecasting the time-series

```{r autopred}
sequence = SequenceSet_get(training_set,0)


 setClass("_p_std__vectorT_std__vectorT_double_std__allocatorT_double_t_t_p_std__allocatorT_std__vectorT_double_std__allocatorT_double_t_t_p_t_t", contains = 'ExternalReference')

#predictor = AutoPredictor__SWIG_2(network, LinearTransferFunction() )
#predictor = AutoPredictor__SWIG_2(network, LinearAddedNoiseTransferFunction(.1) )
predictor = AutoPredictor__SWIG_2(network, LinearDampenedTransferFunction(.99) )

time_steps <- 400
context <- 200
x = AutoPredictor_predict( predictor, sequence, time_steps, context)

```

```{r broken}
vals <- sapply(1:time_steps, FUN = function(index){getRow(x, index-1)})
#getLength(x)
plot(vals,type="l")
#	AutoPredictor predictor2(network, new LinearTransferFunction() );
#		predictor2.predict_and_plot( sequence, sequence->size(), 1000);
```

```{r}
x <- Network_activate_and_return_activations(network, sequence)
num_nodes <- Network_get_num_nodes(network);
ln <- Sequence_size(sequence)
datfr <- matrix(NA, nrow=ln, ncol=num_nodes)
for (i in 1:num_nodes) {
  rowdat<-  getRow(x,i-1)
 datfr[,i] <- rowdat
}

#nodenames <- Network_get_node_names(network)
#getString(nodenames, 0)
```

